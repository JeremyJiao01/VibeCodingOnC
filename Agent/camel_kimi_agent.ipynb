{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 CAMEL 框架搭建 Agent (Kimi k2.5 实践)\n",
    "\n",
    "本教程将带你使用 [CAMEL-AI](https://www.camel-ai.org/) 框架，并结合 Moonshot AI 的 **Kimi k2.5** 模型来构建你的第一个 AI Agent。\n",
    "\n",
    "## 1. 环境准备\n",
    "\n",
    "首先，我们需要安装 `camel-ai` 库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在某些环境下，可能需要使用 python3 -m pip\n",
    "!python3 -m pip install camel-ai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置 Kimi k2.5 API\n",
    "\n",
    "Kimi k2.5 的 API 与 OpenAI 兼容。你需要准备好 Moonshot AI 的 API Key。\n",
    "\n",
    "你可以从 [Moonshot AI 开放平台](https://platform.moonshot.ai/) 获取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"MOONSHOT_API_KEY\" not in os.environ:\n",
    "    os.environ[\"MOONSHOT_API_KEY\"] = getpass(\"请输入你的 Moonshot API Key: \")\n",
    "\n",
    "# 重要：CAMEL 有时会强制检查 OPENAI_API_KEY 环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"MOONSHOT_API_KEY\"]\n",
    "\n",
    "KIMI_BASE_URL = \"https://api.moonshot.ai/v1\"\n",
    "KIMI_MODEL_TYPE = \"kimi-k2.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 初始化 Kimi k2.5 模型\n",
    "\n",
    "使用 CAMEL 的 `ModelFactory` 来创建一个 OpenAI 兼容的模型实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功初始化模型: kimi-k2.5\n"
     ]
    }
   ],
   "source": [
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "\n",
    "kimi_model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=KIMI_MODEL_TYPE,\n",
    "    model_config_dict={\n",
    "        \"api_key\": os.environ[\"MOONSHOT_API_KEY\"],\n",
    "        \"base_url\": KIMI_BASE_URL,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"成功初始化模型: {KIMI_MODEL_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 构建基础 ChatAgent\n",
    "\n",
    "我们先创建一个简单的对话 Agent。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-08 17:00:36,456 - root - WARNING - Unknown model 'kimi-k2.5': context window size not defined. Defaulting to 999_999_999.\n",
      "2026-02-08 17:00:39,631 - camel.models.model_manager - ERROR - Error processing with model: <camel.models.openai_model.OpenAIModel object at 0x105ed22d0>\n",
      "2026-02-08 17:00:39,631 - camel.camel.agents.chat_agent - ERROR - Model error: kimi-k2.5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      9\u001b[39m agent = ChatAgent(\n\u001b[32m     10\u001b[39m     system_message=system_message,\n\u001b[32m     11\u001b[39m     model=kimi_model,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m user_msg = BaseMessage.make_user_message(role_name=\u001b[33m\"\u001b[39m\u001b[33mUser\u001b[39m\u001b[33m\"\u001b[39m, content=\u001b[33m\"\u001b[39m\u001b[33m请简要介绍一下 CAMEL-AI 框架的主要特点。\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.msgs[\u001b[32m0\u001b[39m].content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/agents/chat_agent.py:2838\u001b[39m, in \u001b[36mChatAgent.step\u001b[39m\u001b[34m(self, input_message, response_format)\u001b[39m\n\u001b[32m   2834\u001b[39m future = executor.submit(\n\u001b[32m   2835\u001b[39m     \u001b[38;5;28mself\u001b[39m._step_impl, input_message, response_format\n\u001b[32m   2836\u001b[39m )\n\u001b[32m   2837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2839\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent.futures.TimeoutError:\n\u001b[32m   2840\u001b[39m     future.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/agents/chat_agent.py:2919\u001b[39m, in \u001b[36mChatAgent._step_impl\u001b[39m\u001b[34m(self, input_message, response_format)\u001b[39m\n\u001b[32m   2915\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step_terminate(\n\u001b[32m   2916\u001b[39m         e.args[\u001b[32m1\u001b[39m], tool_call_records, \u001b[33m\"\u001b[39m\u001b[33mmax_tokens_exceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2917\u001b[39m     )\n\u001b[32m   2918\u001b[39m \u001b[38;5;66;03m# Get response from model backend\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_model_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopenai_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurrent_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_schemas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   2924\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_tools\u001b[49m\n\u001b[32m   2925\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_full_tool_schemas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprev_num_openai_messages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprev_num_openai_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2927\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2929\u001b[39m prev_num_openai_messages = \u001b[38;5;28mlen\u001b[39m(openai_messages)\n\u001b[32m   2930\u001b[39m iteration_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/agents/chat_agent.py:3413\u001b[39m, in \u001b[36mChatAgent._get_model_response\u001b[39m\u001b[34m(self, openai_messages, current_iteration, response_format, tool_schemas, prev_num_openai_messages)\u001b[39m\n\u001b[32m   3411\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.retry_attempts):\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopenai_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_schemas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   3415\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3416\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m   3417\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/models/model_manager.py:239\u001b[39m, in \u001b[36mModelManager.run\u001b[39m\u001b[34m(self, messages, response_format, tools)\u001b[39m\n\u001b[32m    237\u001b[39m         \u001b[38;5;66;03m# Skip already used one\u001b[39;00m\n\u001b[32m    238\u001b[39m         \u001b[38;5;28mself\u001b[39m.current_model = \u001b[38;5;28mself\u001b[39m.scheduling_strategy()\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/models/model_manager.py:229\u001b[39m, in \u001b[36mModelManager.run\u001b[39m\u001b[34m(self, messages, response_format, tools)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# Pass all messages to the selected model and get the response\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    231\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing with model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.current_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/models/base_model.py:212\u001b[39m, in \u001b[36mModelBackendMeta.__new__.<locals>.wrapped_run\u001b[39m\u001b[34m(self, messages, *args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mwrapped_run\u001b[39m(\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m, messages: List[OpenAIMessage], *args, **kwargs\n\u001b[32m    210\u001b[39m ):\n\u001b[32m    211\u001b[39m     messages = \u001b[38;5;28mself\u001b[39m.preprocess_messages(messages)\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/models/base_model.py:633\u001b[39m, in \u001b[36mBaseModelBackend.run\u001b[39m\u001b[34m(self, messages, response_format, tools)\u001b[39m\n\u001b[32m    630\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mResponse format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response_format)\n\u001b[32m    631\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mTools: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, tools)\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mResult: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, result)\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# For streaming responses, wrap with logging; otherwise log immediately\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/models/openai_model.py:320\u001b[39m, in \u001b[36mOpenAIModel._run\u001b[39m\u001b[34m(self, messages, response_format, tools)\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_parse(messages, response_format, tools)\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/camel/models/openai_model.py:387\u001b[39m, in \u001b[36mOpenAIModel._request_chat_completion\u001b[39m\u001b[34m(self, messages, tools)\u001b[39m\n\u001b[32m    384\u001b[39m request_config = \u001b[38;5;28mself\u001b[39m._prepare_request_config(tools)\n\u001b[32m    385\u001b[39m request_config = \u001b[38;5;28mself\u001b[39m._sanitize_config(request_config)\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Completions.create() got an unexpected keyword argument 'api_key'"
     ]
    }
   ],
   "source": [
    "from camel.agents import ChatAgent\n",
    "from camel.messages import BaseMessage\n",
    "\n",
    "system_message = BaseMessage.make_assistant_message(\n",
    "    role_name=\"Assistant\",\n",
    "    content=\"你是一个由 Kimi k2.5 驱动的智能助手，能够提供准确、专业的建议。\",\n",
    ")\n",
    "\n",
    "agent = ChatAgent(\n",
    "    system_message=system_message,\n",
    "    model=kimi_model,\n",
    ")\n",
    "\n",
    "user_msg = BaseMessage.make_user_message(role_name=\"User\", content=\"请简要介绍一下 CAMEL-AI 框架的主要特点。\")\n",
    "response = agent.step(user_msg)\n",
    "\n",
    "print(response.msgs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 进阶：角色扮演 (Role-Playing)\n",
    "\n",
    "CAMEL 框架最核心的特点是多智能体协同（Role-Playing）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.societies import RolePlaying\n",
    "\n",
    "task_prompt = \"开发一个简单的待办事项(Todo List)命令行应用，使用 Python 编写。\"\n",
    "\n",
    "role_play_session = RolePlaying(\n",
    "    assistant_role_name=\"Python 程序员\",\n",
    "    user_role_name=\"项目经理\",\n",
    "    task_prompt=task_prompt,\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=KIMI_MODEL_TYPE,\n",
    "    model_config_dict={\n",
    "        \"api_key\": os.environ[\"MOONSHOT_API_KEY\"],\n",
    "        \"base_url\": KIMI_BASE_URL,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"任务: {task_prompt}\")\n",
    "\n",
    "chat_turn_limit = 3\n",
    "input_msg = role_play_session.init_chat()\n",
    "\n",
    "for i in range(chat_turn_limit):\n",
    "    assistant_response, user_response = role_play_session.step(input_msg)\n",
    "    \n",
    "    print(f\"\\n第 {i+1} 轮 ---\")\n",
    "    print(f\"项目经理: {user_response.msg.content[:200]}...\")\n",
    "    print(f\"程序员: {assistant_response.msg.content[:200]}...\")\n",
    "    \n",
    "    input_msg = assistant_response.msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 总结\n",
    "\n",
    "通过这个 Notebook，你已经学会了：\n",
    "1. 如何配置 CAMEL-AI 使用自定义的 OpenAI 兼容模型（Kimi k2.5）。\n",
    "2. 如何创建单个 ChatAgent 进行对话。\n",
    "3. 如何使用 `RolePlaying` 启动多智能体协作。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
